{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.5\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b98b58f180ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# stop words are words that have no significance to machines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words\n",
    "# stop words are words that have no significance to machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Dave watched as the forest burned up on the hill,\n",
    "only a few miles from his house. The car had\n",
    "been hastily packed and Marta was inside trying to round\n",
    "up the last of the pets. \"Where could she be?\" he wondered\n",
    "as he continued to wait for Marta to appear with the pets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n, Dave, watched, as, the, forest, burned, up, on, the, hill, ,, \n, only, a, few, miles, from, his, house, ., The, car, had, \n, been, hastily, packed, and, Marta, was, inside, trying, to, round, \n, up, the, last, of, the, pets, ., \", Where, could, she, be, ?, \", he, wondered, \n, as, he, continued, to, wait, for, Marta, to, appear, with, the, pets, ., \n]\n[\n, Dave, watched, forest, burned, hill, ,, \n, miles, house, ., car, \n, hastily, packed, Marta, inside, trying, round, \n, pets, ., \", ?, \", wondered, \n, continued, wait, Marta, appear, pets, ., \n]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "document = nlp(text)\n",
    "tokens = []\n",
    "filtered_tokens = []\n",
    "for i in document:\n",
    "    tokens.append(i)\n",
    "print(tokens)\n",
    "for i in document:\n",
    "    if not i.is_stop:\n",
    "        filtered_tokens.append(i)\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(directory = \"aclImdb/train\", split = 0.8, limit=0):\n",
    "    reviews =[]\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        data_directory = directory+\"/\"+label.replace(\" \",\"\")\n",
    "        for review in os.listdir(data_directory):\n",
    "            if review.endswith(\".txt\"):\n",
    "                thefile= data_directory+\"/\"+review.replace(\" \",\"\")\n",
    "                f = open(thefile, encoding='utf-8')\n",
    "                text = f.read()\n",
    "                text = text.replace(\"<br />\", \"\\n\\n\")\n",
    "                if text.strip():\n",
    "                    spacy_label= {\n",
    "                        \"cats\": {\n",
    "                            \"pos\": \"pos\" == label,\n",
    "                            \"neg\": \"neg\" == label\n",
    "                        }\n",
    "                    }\n",
    "                    reviews.append((text, spacy_label))\n",
    "    random.shuffle(reviews)\n",
    "\n",
    "    if limit:\n",
    "        reviews = reviews[:limit]\n",
    "    split = int(len(reviews)*split)\n",
    "    return reviews[:split], reviews[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data, test_data, iter = 20):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    else:\n",
    "        textcat =nlp.get_pipe(\"textcat\")\n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label(\"neg\")\n",
    "    excluded_pipes = []\n",
    "    for pipe in nlp.pipe_names:\n",
    "        if pipe != \"textcat\":\n",
    "            excluded_pipes.append(pipe)   \n",
    "    with nlp.disable_pipes(excluded_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        print(\"Beginning training\")\n",
    "        print(\"Loss\\tPrecision\\tRecall\\tF Score\")        \n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001) \n",
    "\n",
    "        for i in range(iter):\n",
    "            loss={}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                text, label = zip(*batch)\n",
    "                nlp.update(text, label, drop=0.2, sgd=optimizer, losses=loss)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                eval_results = evaluate(token=nlp.tokenizer, textcat=textcat, test_data=test_data)\n",
    "                print(\n",
    "                    f\"{loss['textcat']}\\t{eval_results['precision']}\"\n",
    "                    f\"\\t{eval_results['recall']}\"\n",
    "                    f\"\\t{eval_results['f-score']}\"\n",
    "                )\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(\"model_artifacts\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(token, textcat, test_data):\n",
    "    reviews, labels = zip(*test_data)\n",
    "    reviews = (token(review) for review in reviews)\n",
    "    true_positives = 0\n",
    "    false_positives = 1e-8  # Can't be 0 because of presence in denominator\n",
    "    true_negatives = 0\n",
    "    false_negatives = 1e-8\n",
    "    for i, review in enumerate(textcat.pipe(reviews)):\n",
    "        true_label = labels[i][\"cats\"]\n",
    "        for predicted_label, score in review.cats.items():\n",
    "            # Every cats dictionary includes both labels. You can get all\n",
    "            # the info you need with just the pos label.\n",
    "            if (\n",
    "                predicted_label == \"neg\"\n",
    "            ):\n",
    "                continue\n",
    "            if score >= 0.5 and true_label[\"pos\"]:\n",
    "                true_positives += 1\n",
    "            elif score >= 0.5 and true_label[\"neg\"]:\n",
    "                false_positives += 1\n",
    "            elif score < 0.5 and true_label[\"neg\"]:\n",
    "                true_negatives += 1\n",
    "            elif score < 0.5 and true_label[\"pos\"]:\n",
    "                false_negatives += 1\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    if (precision + recall == 0):\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f-score\": f_score}            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REVIEW = \"\"\"\n",
    "Transcendently beautiful in moments outside the office, it seems almost\n",
    "sitcom-like in those scenes. When Toni Colette walks out and ponders\n",
    "life silently, it's gorgeous.<br /><br />The movie doesn't seem to decide\n",
    "whether it's slapstick, farce, magical realism, or drama, but the best of it\n",
    "doesn't matter. (The worst is sort of tedious - like Office Space with less humor.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REVIEW = \"\"\"\n",
    "Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(input_data):\n",
    "    loaded_model = spacy.load(\"model_artifacts\")\n",
    "    parsed_text = loaded_model(input_data)\n",
    "    if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
    "        prediction = \"Positive\"\n",
    "        score = parsed_text.cats[\"pos\"]\n",
    "    else:\n",
    "        prediction = \"Negative\"\n",
    "        score = parsed_text.cats[\"neg\"]\n",
    "    print(\n",
    "        f\"Review text: {input_data}\\nPredicted sentiment: {prediction}\"\n",
    "        f\"\\tScore: {score}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Beginning training\n",
      "Loss\tPrecision\tRecall\tF Score\n",
      "0.20788690075278282\t0.9999999900000002\t0.9999999900000002\t0.9999999900000002\n",
      "0.14933563582599163\t0.9999999900000002\t0.9999999900000002\t0.9999999900000002\n",
      "0.1055685542523861\t0.3333333322222222\t0.9999999900000002\t0.4999999975\n",
      "0.07138955779373646\t0.1999999996\t0.9999999900000002\t0.3333333322222222\n",
      "0.039759696228429675\t0.0\t0.0\t0\n",
      "0.025101906736381352\t0.0\t0.0\t0\n",
      "0.013253693177830428\t0.0\t0.0\t0\n",
      "0.006646072382864077\t0.249999999375\t0.9999999900000002\t0.3999999984\n",
      "0.007640088972038939\t0.249999999375\t0.9999999900000002\t0.3999999984\n",
      "0.0006134375653346069\t0.0\t0.0\t0\n",
      "0.0016132568098328193\t0.0\t0.0\t0\n",
      "0.0005215432281602261\t0.0\t0.0\t0\n",
      "0.0005037493647250813\t0.249999999375\t0.9999999900000002\t0.3999999984\n",
      "0.0005321603803167818\t0.249999999375\t0.9999999900000002\t0.3999999984\n",
      "0.00011954715273532202\t0.249999999375\t0.9999999900000002\t0.3999999984\n",
      "0.00015557168262603227\t0.249999999375\t0.9999999900000002\t0.3999999984\n",
      "8.997715627856451e-05\t0.0\t0.0\t0\n",
      "0.00023383845666558045\t0.0\t0.0\t0\n",
      "4.173337205770622e-05\t0.0\t0.0\t0\n",
      "0.000123855702270248\t0.0\t0.0\t0\n",
      "Testing model\n",
      "Review text: \n",
      "Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\n",
      "\n",
      "Predicted sentiment: Negative\tScore: 0.6583472490310669\n"
     ]
    }
   ],
   "source": [
    "train, test = load_training_data(limit=25)\n",
    "train_model(train,test)\n",
    "print(\"Testing model\")\n",
    "test_model(TEST_REVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}